{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating a generative AI with `twinLab`\n",
    "\n",
    "In the language of AI models, the word `generative` means that we train a model to learn a statistical distribution of $y$, rather than just a point estimate of $y$. In this way, the Gaussian Processes used by `twinLab` are naturally generative models, and we can use these to make a crude generative AI model for images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard imports\n",
    "import pickle\n",
    "\n",
    "# Third-party imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# twinLab\n",
    "import twinlab as tl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "\n",
    "# Experiment\n",
    "# experiment = \"MNIST-lowres\" # 8x8 images\n",
    "experiment = \"MNIST\" # 28x28 images\n",
    "# experiment = \"CIFAR-10\" # https://www.cs.toronto.edu/~kriz/cifar.html \n",
    "\n",
    "# Random numbers\n",
    "random_seed = 123\n",
    "\n",
    "# Training parameters\n",
    "training_samples = 1500\n",
    "explained_variance = 0.5\n",
    "onehot_encode = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions\n",
    "def unpickle(file): \n",
    "    with open(file, \"rb\") as fo:\n",
    "        dict = pickle.load(fo, encoding=\"bytes\")\n",
    "    return dict\n",
    "\n",
    "def wrangle_image(linear_image, npix): \n",
    "    # Reshape a CIFAR-10 image\n",
    "    pix = npix**2\n",
    "    if len(linear_image) == pix:\n",
    "        image = linear_image.reshape(npix, npix)\n",
    "    elif len(linear_image) == 3*pix:\n",
    "        R = linear_image[0*pix:1*pix].reshape(npix, npix)\n",
    "        G = linear_image[1*pix:2*pix].reshape(npix, npix)\n",
    "        B = linear_image[2*pix:3*pix].reshape(npix, npix)\n",
    "        image = np.dstack((R, G, B)).astype(np.uint8)\n",
    "    else:\n",
    "        raise ValueError(\"Image is neither 1D nor 3D.\")\n",
    "    return image\n",
    "\n",
    "def plot_images(df, nrow, ncol, figx, figy, npix, vmin=0., vmax=255.):\n",
    "    iplot = 0\n",
    "    plt.subplots(nrow, ncol, figsize=(figx*ncol, figy*nrow))\n",
    "    for _ in range(nrow):\n",
    "        for _ in range(ncol):\n",
    "            image = wrangle_image(df.iloc[iplot].to_numpy(), npix)\n",
    "            iplot += 1\n",
    "            plt.subplot(nrow, ncol, iplot)\n",
    "            plt.imshow(image, cmap=\"binary_r\", vmin=vmin, vmax=vmax)\n",
    "            plt.xticks([]); plt.yticks([])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculations\n",
    "np.random.seed(random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if experiment == \"MNIST-lowres\":\n",
    "\n",
    "    # Read data in and set pixels that the training data has \n",
    "    # In this case, it's 8x8 pixel pictures of numbers 0 to 9. 1798 pictures\n",
    "    npix = 8\n",
    "    filepath = \"MNIST-lowres/data.csv\"\n",
    "    df = pd.read_csv(filepath)\n",
    "\n",
    "elif experiment == \"MNIST\":\n",
    "\n",
    "    # 10,000 examples of 28x28 pixel pictures of numbers 0 to 9\n",
    "    npix = 28\n",
    "    filepath = \"MNIST/test.csv\"\n",
    "    df = pd.read_csv(filepath)\n",
    "    df.rename({\"label\": \"number\"}, axis=\"columns\", inplace=True)\n",
    "\n",
    "elif experiment == \"CIFAR-10\":\n",
    "\n",
    "    # 32x32 pixel pictures. 10 pictures of 10 different types of object \n",
    "    npix = 32\n",
    "    filepath = \"CIFAR-10/data_batch_1\"\n",
    "    data = unpickle(filepath)\n",
    "\n",
    "    # Iterate through the RGB values that compose these pictures \n",
    "    # Each pixel gets a value so we can unpack a 3D object into the 2D dataframe\n",
    "    df = pd.DataFrame(data[b\"data\"])\n",
    "    df.columns = [f\"{RGB}-{i}-{j}\" for RGB in [\"R\", \"G\", \"B\"] for i in range(npix) for j in range(npix)]\n",
    "    df[\"number\"] = data[b\"labels\"] #Â TODO: Try to insert this as the first column\n",
    "    image_dict = {\n",
    "        \"airplane\": 0,\n",
    "        \"automobile\": 1,\n",
    "        \"bird\": 2,\n",
    "        \"cat\": 3,\n",
    "        \"deer\": 4,\n",
    "        \"dog\": 5,\n",
    "        \"frog\": 6,\n",
    "        \"horse\": 7,\n",
    "        \"ship\": 8,\n",
    "        \"truck\": 9\n",
    "    }\n",
    "    df = df[df[\"number\"] == image_dict[\"dog\"]] # TODO: Only dogs for tests!\n",
    "\n",
    "else:\n",
    "    raise ValueError(\"Experiement not recognised\")\n",
    "\n",
    "# One-hot encoding\n",
    "if onehot_encode:\n",
    "    df = pd.get_dummies(df, columns=[\"number\"])\n",
    "\n",
    "# Set up campaign\n",
    "if onehot_encode:\n",
    "    inputs = [f\"number_{i}\" for i in range(10)]\n",
    "else:\n",
    "    inputs = [\"number\"]\n",
    "outputs = list(df.drop(columns=inputs))\n",
    "\n",
    "# Print to screen\n",
    "display(df)\n",
    "\n",
    "# Plot an image of the data\n",
    "nrow, ncol = 10, 10\n",
    "figx, figy = 1.2, 1.2\n",
    "plot_images(df[outputs], nrow, ncol, figx, figy, npix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup campaign\n",
    "setup_dict = {\n",
    "    \"inputs\": inputs,\n",
    "    \"outputs\": outputs,\n",
    "    'estimator': 'gaussian_process_regression', # What type of model do you want to use? \n",
    "    'decompose_outputs': True, # Equivalent of PCA/SVD; necessary to learn structure\n",
    "    'output_explained_variance': explained_variance # Toggle this number to improve accuracy\n",
    "}\n",
    "campaign = tl.Campaign(**setup_dict)\n",
    "\n",
    "# Train campaign\n",
    "train_dict = {\n",
    "    \"df\": df,\n",
    "    \"train_test_split\": training_samples, # How many rows are used for training?\n",
    "}\n",
    "campaign.fit(**train_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show some diagnostic information about the trained campaign\n",
    "campaign.get_diagnostics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make some predictions\n",
    "df_predict = pd.DataFrame({'number': list(range(10))})\n",
    "if onehot_encode:\n",
    "    df_predict = pd.get_dummies(df_predict, columns=[\"number\"])\n",
    "display(df_predict)\n",
    "\n",
    "# Pull out the mean prediction\n",
    "df_mean, _ = campaign.predict(df_predict)\n",
    "display(df_mean)\n",
    "\n",
    "# Plot the mean value of each figure/number from the trained dataset\n",
    "nrow, ncol = 2, 5\n",
    "figx, figy = 2, 2\n",
    "plot_images(df_mean, nrow, ncol, figx, figy, npix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate some weird numbers\n",
    "if onehot_encode:\n",
    "    nrow = 90\n",
    "    df_predict = pd.DataFrame(np.zeros((nrow, 10)))\n",
    "    df_predict.columns = [f\"number_{icol}\" for icol in range(10)]\n",
    "    for irow in range(nrow):\n",
    "        icol = irow % 10\n",
    "        inum1 = irow // 10\n",
    "        inum2 = inum1 + 1\n",
    "        ifrac = icol/10\n",
    "        ifrac1, ifrac2 = 1-ifrac, ifrac\n",
    "        df_predict[f\"number_{inum1}\"].iloc[irow] = ifrac1\n",
    "        df_predict[f\"number_{inum2}\"].iloc[irow] = ifrac2\n",
    "else:\n",
    "    df_predict = pd.DataFrame({'number': np.linspace(0, 8.9, 90)})\n",
    "display(df_predict)\n",
    "\n",
    "# Make predictions\n",
    "df_mean, _ = campaign.predict(df_predict)\n",
    "display(df_mean)\n",
    "\n",
    "# Plot\n",
    "nrow, ncol = 9, 10\n",
    "figx, figy = 1.2, 1.2\n",
    "plot_images(df_mean, nrow, ncol, figx, figy, npix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate samples from the trained model\n",
    "nsample = 10\n",
    "df_predict = pd.DataFrame({'number': list(range(10))})\n",
    "if onehot_encode:\n",
    "    df_predict = pd.get_dummies(df_predict, columns=[\"number\"])\n",
    "display(df_predict)\n",
    "\n",
    "# Generate samples\n",
    "df_samples = campaign.sample(df_predict, nsample, {\"observation_noise\": True}) # NOTE: \"observation_noise\" needs to be true in order to generate diverse samples\n",
    "df_samples = df_samples.stack(level=1).reset_index(1).rename(columns={\"level_1\": \"sample\"})\n",
    "display(df_samples)\n",
    "\n",
    "# Plot\n",
    "nrow, ncol = 10, nsample\n",
    "figx, figy = 1.2, 1.2\n",
    "plot_images(df_samples[outputs], nrow, ncol, figx, figy, npix)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
