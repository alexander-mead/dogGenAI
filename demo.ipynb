{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a generative AI with twinlab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard imports\n",
    "import pickle\n",
    "\n",
    "# Third-party imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# twinLab\n",
    "import twinlab as tl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "\n",
    "# Experiment\n",
    "# experiment = \"MNIST-lowres\" # 8x8 images\n",
    "experiment = \"MNIST\" # 28x28 images\n",
    "# experiment = \"CIFAR-10\" # https://www.cs.toronto.edu/~kriz/cifar.html \n",
    "\n",
    "# Random numbers\n",
    "random_seed = 123\n",
    "\n",
    "# Training parameters\n",
    "training_samples = 1500\n",
    "explained_variance = 0.5\n",
    "onehot_encode = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions\n",
    "def unpickle(file): \n",
    "    with open(file, \"rb\") as fo:\n",
    "        dict = pickle.load(fo, encoding=\"bytes\")\n",
    "    return dict\n",
    "\n",
    "def wrangle_image(linear_image, npix): \n",
    "    # Reshape a CIFAR-10 image\n",
    "    pix = npix**2\n",
    "    if len(linear_image) == pix:\n",
    "        image = linear_image.reshape(npix, npix)\n",
    "    elif len(linear_image) == 3*pix:\n",
    "        R = linear_image[0*pix:1*pix].reshape(npix, npix)\n",
    "        G = linear_image[1*pix:2*pix].reshape(npix, npix)\n",
    "        B = linear_image[2*pix:3*pix].reshape(npix, npix)\n",
    "        image = np.dstack((R, G, B)).astype(np.uint8)\n",
    "    else:\n",
    "        raise ValueError(\"Image is neither 1D nor 3D.\")\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculations\n",
    "np.random.seed(random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if experiment == \"MNIST-lowres\":\n",
    "\n",
    "    # Read data in and set pixels that the training data has \n",
    "    # In this case, it's 8x8 pixel pictures of numbers 0 to 9. 1798 pictures\n",
    "    npix = 8\n",
    "    filepath = \"MNIST-lowres/data.csv\"\n",
    "    df = pd.read_csv(filepath)\n",
    "\n",
    "elif experiment == \"MNIST\":\n",
    "\n",
    "    # 10,000 examples of 28x28 pixel pictures of numbers 0 to 9\n",
    "    npix = 28\n",
    "    filepath = \"MNIST/test.csv\"\n",
    "    df = pd.read_csv(filepath)\n",
    "    df.rename({\"label\": \"number\"}, axis=\"columns\", inplace=True)\n",
    "\n",
    "elif experiment == \"CIFAR-10\":\n",
    "\n",
    "    # 32x32 pixel pictures. 10 pictures of 10 different types of object \n",
    "    npix = 32\n",
    "    filepath = \"CIFAR-10/data_batch_1\"\n",
    "    data = unpickle(filepath)\n",
    "\n",
    "    # Iterate through the RGB values that compose these pictures \n",
    "    # Each pixel gets a value so we can unpack a 3D object into the 2D dataframe\n",
    "    df = pd.DataFrame(data[b\"data\"])\n",
    "    df.columns = [f\"{RGB}-{i}-{j}\" for RGB in [\"R\", \"G\", \"B\"] for i in range(npix) for j in range(npix)]\n",
    "    df[\"number\"] = data[b\"labels\"] #Â TODO: Try to insert this as the first column\n",
    "    image_dict = {\n",
    "        \"airplane\": 0,\n",
    "        \"automobile\": 1,\n",
    "        \"bird\": 2,\n",
    "        \"cat\": 3,\n",
    "        \"deer\": 4,\n",
    "        \"dog\": 5,\n",
    "        \"frog\": 6,\n",
    "        \"horse\": 7,\n",
    "        \"ship\": 8,\n",
    "        \"truck\": 9\n",
    "    }\n",
    "    df = df[df[\"number\"] == image_dict[\"dog\"]] # TODO: Only dogs for tests!\n",
    "\n",
    "else:\n",
    "    raise ValueError(\"Experiement not recognised\")\n",
    "\n",
    "# One-hot encoding\n",
    "if onehot_encode:\n",
    "    df = pd.get_dummies(df, columns=[\"number\"])\n",
    "\n",
    "# Set up campaign\n",
    "if onehot_encode:\n",
    "    inputs = [f\"number_{i}\" for i in range(10)]\n",
    "else:\n",
    "    inputs = [\"number\"]\n",
    "outputs = list(df.drop(columns=inputs))\n",
    "\n",
    "# Print to screen\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot an image of the data\n",
    "plt.subplots(10, 10, figsize=(10, 10))\n",
    "for i in range(100):\n",
    "    plt.subplot(10, 10, i+1)\n",
    "    image = wrangle_image(df[outputs].iloc[i].to_numpy(), npix)\n",
    "    plt.imshow(image, cmap=\"binary_r\", vmin=0., vmax=255.)\n",
    "    plt.xticks([]); plt.yticks([])\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data campaign"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup campaign\n",
    "setup_dict = {\n",
    "    \"inputs\": inputs,\n",
    "    \"outputs\": outputs,\n",
    "    'estimator': 'gaussian_process_regression', # What type of model do you want to use? \n",
    "    'decompose_outputs': True, # Equivalent of PCA/SVD; necessary to learn structure\n",
    "    'output_explained_variance': explained_variance # Toggle this number to improve accuracy\n",
    "}\n",
    "campaign = tl.Campaign(**setup_dict)\n",
    "\n",
    "# Train campaign\n",
    "train_dict = {\n",
    "    \"df\": df,\n",
    "    \"train_test_split\": training_samples, # How many rows are used for training?\n",
    "}\n",
    "campaign.fit(**train_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show some diagnostic information about the trained campaign\n",
    "campaign.get_diagnostics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make some predictions\n",
    "df_predict = pd.DataFrame({'number': list(range(10))})\n",
    "if onehot_encode:\n",
    "    df_predict = pd.get_dummies(df_predict, columns=[\"number\"])\n",
    "# df_predict = pd.DataFrame({'number': np.linspace(0.5, 9.5, 10)})\n",
    "# df_predict = pd.DataFrame({'number': np.linspace(5.5, 6.4, 10)})\n",
    "display(df_predict)\n",
    "\n",
    "# Pull out the mean and true to the prediction of the campaign\n",
    "# Could also pull out the standard deviation (std), not sure if this is useful\n",
    "df_mean, _ = campaign.predict(df_predict)\n",
    "display(df_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the mean value of each figure/number from the trained dataset\n",
    "plt.subplots(2, 5, figsize=(10, 4))\n",
    "iplot = 0\n",
    "for row in range(10):\n",
    "    iplot += 1\n",
    "    plt.subplot(2, 5, iplot)\n",
    "    image = wrangle_image(df_mean.iloc[row].to_numpy(), npix)\n",
    "    plt.imshow(image, cmap=\"binary_r\", vmin=0., vmax=255.)\n",
    "    plt.xticks([]); plt.yticks([])\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate some random samples from the trained model\n",
    "# Note that \"observation_noise\" needs to be true in order to generate diverse samples\n",
    "nsample = 5\n",
    "df_samples = campaign.sample(df_predict, nsample, {\"observation_noise\": True})\n",
    "# display(df_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot rsamples of each type of image from the trained model\n",
    "nrow, ncol = nsample, 10\n",
    "plt.subplots(nrow, ncol, figsize=(20, 2*nsample))\n",
    "iplot = 0\n",
    "for sample in range(nsample):\n",
    "    for number in range(10):\n",
    "        iplot += 1\n",
    "        plt.subplot(nrow, ncol, iplot)\n",
    "        linear_image = df_samples.xs(sample, axis=\"columns\", level=1, drop_level=True).iloc[number].to_numpy()\n",
    "        image = wrangle_image(linear_image, npix)\n",
    "        plt.imshow(image, cmap=\"binary_r\", vmin=0., vmax=255.)\n",
    "        plt.xticks([]); plt.yticks([])\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
